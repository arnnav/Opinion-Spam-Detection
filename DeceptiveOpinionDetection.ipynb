{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello!!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\sumit_hzrt\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "nltk.download('punkt')\n",
    "print(\"Hello!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/positive_polarity/deceptive_from_MTurk/fold',\n",
       " 'data/positive_polarity/truthful_from_TripAdvisor/fold']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rootpath = 'data/positive_polarity/'\n",
    "basepaths = [rootpath + 'deceptive_from_MTurk/fold', rootpath + 'truthful_from_TripAdvisor/fold']\n",
    "basepaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80\n",
      "80\n"
     ]
    }
   ],
   "source": [
    "def create_data_list(basepath):\n",
    "    k_fold_data = []\n",
    "    for i in range(1, k+1):\n",
    "        data = []\n",
    "        path = basepath + str(i)\n",
    "        with os.scandir(path) as entries:\n",
    "            for entry in entries:\n",
    "                with open(entry, encoding=\"utf8\") as file:\n",
    "                    data.append(file.readline())\n",
    "        k_fold_data.append(data)\n",
    "    return k_fold_data\n",
    "\n",
    "# k_fold_data -> list of list ([<review_text>])\n",
    "k_fold_data_deceptive = create_data_list(basepaths[0])\n",
    "k_fold_data_true = create_data_list(basepaths[1])\n",
    "\n",
    "print(len(k_fold_data_deceptive[0]))\n",
    "print(len(k_fold_data_true[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 46753"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46753\n",
      "46753\n"
     ]
    }
   ],
   "source": [
    "def build_bigram_plus_dict(k_fold_data, bigram_plus_dict):\n",
    "#     stemmer = PorterStemmer()\n",
    "    bigram_plus_set = set(bigram_plus_dict)\n",
    "\n",
    "    for data in k_fold_data:\n",
    "        for text in data:\n",
    "            tokens = word_tokenize(text)\n",
    "#             stemmed_tokens = [stemmer.stem(token.lower()) for token in tokens]\n",
    "            \n",
    "            # adding unigrams\n",
    "            for unigram in tokens:\n",
    "                if not unigram in bigram_plus_set:\n",
    "                    bigram_plus_set.add(unigram)\n",
    "                    bigram_plus_dict.append(unigram)\n",
    "            \n",
    "            # adding bigrams\n",
    "            for bigram in list(nltk.bigrams(tokens)):\n",
    "                if not bigram in bigram_plus_set:\n",
    "                    bigram_plus_dict.append(bigram)\n",
    "                    bigram_plus_set.add(bigram)\n",
    "                    \n",
    "    return bigram_plus_dict\n",
    "\n",
    "bigram_plus_dict = []\n",
    "bigram_plus_dict = build_bigram_plus_dict(k_fold_data_true, bigram_plus_dict)\n",
    "bigram_plus_dict = build_bigram_plus_dict(k_fold_data_deceptive, bigram_plus_dict)\n",
    "\n",
    "# reverse dict\n",
    "bigram_plus_reverse_dict = {v: k for k, v in enumerate(bigram_plus_dict)}\n",
    "print(len(bigram_plus_dict))\n",
    "print(len(bigram_plus_reverse_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_document_vector(data, bigram_plus_reverse_dict):\n",
    "    reviews = np.empty((0, len(bigram_plus_reverse_dict)), dtype = np.float64)\n",
    "#     print(reviews.shape)\n",
    "    for text in data:\n",
    "        review = np.zeros((1, len(bigram_plus_reverse_dict)), dtype = np.float64)\n",
    "        tokens = word_tokenize(text)\n",
    "        \n",
    "        for unigram in tokens:\n",
    "            review[0][bigram_plus_reverse_dict[unigram]]+=1\n",
    "                    \n",
    "        for bigram in list(nltk.bigrams(tokens)):\n",
    "            review[0][bigram_plus_reverse_dict[bigram]]+=1\n",
    "            \n",
    "        review = preprocessing.normalize(review, norm='l2')\n",
    "        reviews = np.append(reviews, review, axis = 0)\n",
    "    \n",
    "    return reviews\n",
    "\n",
    "# document_vector = create_document_vector(k_fold_data_true[0], bigram_plus_reverse_dict)\n",
    "# np.sqrt(np.sum(document_vector**2, axis=1))   # --> to check summation of normalized vector is one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm(k_fold_data_true, k_fold_data_deceptive, bigram_plus_reverse_dict):\n",
    "    \n",
    "    params_grid = [{'kernel': ['linear'], 'C': [1, 10, 100, 1000]}]\n",
    "    \n",
    "#     final_svm_model = None\n",
    "    \n",
    "    # 0 -> true, 1 -> deceptive\n",
    "    for i in range(k):\n",
    "        print('Fold', str(i+1), ' as Test Dataset')\n",
    "        \n",
    "        test_x = create_document_vector(k_fold_data_true[i], bigram_plus_reverse_dict)\n",
    "        test_y = np.zeros(len(k_fold_data_true[i]))\n",
    "        \n",
    "        test_x = np.append(test_x, create_document_vector(k_fold_data_deceptive[i], bigram_plus_reverse_dict), axis = 0)\n",
    "        test_y = np.append(test_y, np.ones(len(k_fold_data_deceptive[i])))\n",
    "        \n",
    "        \n",
    "        train_x = None\n",
    "        train_y = None\n",
    "        isFirst = True\n",
    "        \n",
    "        for j in range(k):\n",
    "            if i == j:\n",
    "                continue\n",
    "                \n",
    "            true_reviews = create_document_vector(k_fold_data_true[j], bigram_plus_reverse_dict)\n",
    "            deceptive_reviews = create_document_vector(k_fold_data_deceptive[j], bigram_plus_reverse_dict)\n",
    "            \n",
    "            if isFirst == True:\n",
    "                isFirst = False\n",
    "                train_x = true_reviews\n",
    "                train_y = np.zeros(true_reviews.shape[0])\n",
    "                \n",
    "                train_x = np.append(train_x, deceptive_reviews, axis=0)\n",
    "                train_y = np.append(train_y, np.ones(deceptive_reviews.shape[0]))\n",
    "            else:\n",
    "                train_x = np.append(train_x, true_reviews, axis=0)\n",
    "                train_y = np.append(train_y, np.zeros(true_reviews.shape[0]))\n",
    "                \n",
    "                train_x = np.append(train_x, deceptive_reviews, axis=0)\n",
    "                train_y = np.append(train_y, np.ones(deceptive_reviews.shape[0]))\n",
    "        \n",
    "        print('\\t' + 'Shape-> Train_x: ', train_x.shape, ' Train_y: ', train_y.shape, ' Test_x: ', test_x.shape, ' Test_y: ', test_y.shape)\n",
    "        svm_model = GridSearchCV(SVC(), params_grid, cv=5)\n",
    "        svm_model.fit(train_x, train_y)\n",
    "\n",
    "        # View the training accuracy score\n",
    "        print('\\t Best score for training data:', svm_model.best_score_,\"\\n\") \n",
    "\n",
    "        # View the best parameters for the model found using grid search\n",
    "        print('\\t Best C:',svm_model.best_estimator_.C,\"\\n\") \n",
    "\n",
    "        best_model = svm_model.best_estimator_\n",
    "        \n",
    "        test_y_predicted = best_model.predict(test_x)\n",
    "        print(classification_report(test_y, test_y_predicted))\n",
    "        print('\\t' + '\\033[1m' + \"Training set score for SVM: %f\" % best_model.score(train_x , train_y))\n",
    "        print('\\t' + '\\033[1m' + \"Test  set score for SVM: %f\" % best_model.score(test_x , test_y ))\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1  as Test Dataset\n",
      "\tShape-> Train_x:  (640, 46753)  Train_y:  (640,)  Test_x:  (160, 46753)  Test_y:  (160,)\n",
      "\t Best score for training data: 0.88125 \n",
      "\n",
      "\t Best C: 10 \n",
      "\n",
      "\t              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.88      0.88        80\n",
      "         1.0       0.88      0.89      0.88        80\n",
      "\n",
      "    accuracy                           0.88       160\n",
      "   macro avg       0.88      0.88      0.88       160\n",
      "weighted avg       0.88      0.88      0.88       160\n",
      "\n",
      "\t\u001b[1mTraining set score for SVM: 1.000000\n",
      "\t\u001b[1mTest  set score for SVM: 0.881250\n",
      "Fold 2  as Test Dataset\n",
      "\tShape-> Train_x:  (640, 46753)  Train_y:  (640,)  Test_x:  (160, 46753)  Test_y:  (160,)\n",
      "\t Best score for training data: 0.8640625 \n",
      "\n",
      "\t Best C: 10 \n",
      "\n",
      "\t              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.95      0.93        80\n",
      "         1.0       0.95      0.90      0.92        80\n",
      "\n",
      "    accuracy                           0.93       160\n",
      "   macro avg       0.93      0.93      0.92       160\n",
      "weighted avg       0.93      0.93      0.92       160\n",
      "\n",
      "\t\u001b[1mTraining set score for SVM: 1.000000\n",
      "\t\u001b[1mTest  set score for SVM: 0.925000\n",
      "Fold 3  as Test Dataset\n",
      "\tShape-> Train_x:  (640, 46753)  Train_y:  (640,)  Test_x:  (160, 46753)  Test_y:  (160,)\n",
      "\t Best score for training data: 0.8640625 \n",
      "\n",
      "\t Best C: 10 \n",
      "\n",
      "\t              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.90      0.91        80\n",
      "         1.0       0.90      0.91      0.91        80\n",
      "\n",
      "    accuracy                           0.91       160\n",
      "   macro avg       0.91      0.91      0.91       160\n",
      "weighted avg       0.91      0.91      0.91       160\n",
      "\n",
      "\t\u001b[1mTraining set score for SVM: 1.000000\n",
      "\t\u001b[1mTest  set score for SVM: 0.906250\n",
      "Fold 4  as Test Dataset\n",
      "\tShape-> Train_x:  (640, 46753)  Train_y:  (640,)  Test_x:  (160, 46753)  Test_y:  (160,)\n",
      "\t Best score for training data: 0.8921875 \n",
      "\n",
      "\t Best C: 10 \n",
      "\n",
      "\t              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.86      0.89      0.87        80\n",
      "         1.0       0.88      0.85      0.87        80\n",
      "\n",
      "    accuracy                           0.87       160\n",
      "   macro avg       0.87      0.87      0.87       160\n",
      "weighted avg       0.87      0.87      0.87       160\n",
      "\n",
      "\t\u001b[1mTraining set score for SVM: 1.000000\n",
      "\t\u001b[1mTest  set score for SVM: 0.868750\n",
      "Fold 5  as Test Dataset\n",
      "\tShape-> Train_x:  (640, 46753)  Train_y:  (640,)  Test_x:  (160, 46753)  Test_y:  (160,)\n",
      "\t Best score for training data: 0.871875 \n",
      "\n",
      "\t Best C: 10 \n",
      "\n",
      "\t              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.89      0.89        80\n",
      "         1.0       0.89      0.90      0.89        80\n",
      "\n",
      "    accuracy                           0.89       160\n",
      "   macro avg       0.89      0.89      0.89       160\n",
      "weighted avg       0.89      0.89      0.89       160\n",
      "\n",
      "\t\u001b[1mTraining set score for SVM: 1.000000\n",
      "\t\u001b[1mTest  set score for SVM: 0.893750\n"
     ]
    }
   ],
   "source": [
    "svm(k_fold_data_true, k_fold_data_deceptive, bigram_plus_reverse_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
